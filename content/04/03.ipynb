{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这一节我们主要学习\n",
    "+ Keras 简介\n",
    "+ 用 Keras 实现手写数字识别模型\n",
    "+ 小批量梯度下降（Mini-batch Gradient Descent）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Keras 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ TensorFlow、theano 的特点：方便灵活但是难以上手；\n",
    "+ Keras 是 TensorFlow 和 theano 的接口，容易上手使用且具备一定的灵活性；\n",
    "+ Documentation: <font size=3.5> http://keras.io/ </font>\n",
    "+ Example: <font size=3.5> https://github.com/fchollet/keras/tree/master/examples </font>\n",
    "+ 用 Keras 实现深度学习，就像是在搭积木。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 用 Keras 实现深度学习的“Hello World！” —— 手写数字识别模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1  手写数字识别\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/15-4 手写数字识别.png)\n",
    "+ MNIST Data: <font size=3.5> http://yann.lecun.com/exdb/mnist/ </font>\n",
    "+ Keras 提供数据集加载功能: <font size=3.5> http://keras.io/datasets/ </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 构建网络\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/15-5 构建网络.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 评价模型的好坏\n",
    "\n",
    "\n",
    "+ loss=‘categorical_crossentropy’\n",
    "+ Keras 中损失函数的几种选择：<font size=3.5> https://keras.io/objectives/ </font >\n",
    "\n",
    "![](http://imgbed.momodel.cn/15-6 轮廓123.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 选择最佳的函数——训练\n",
    "\n",
    "\n",
    "+ 第一步，配置优化方式\n",
    "\n",
    "![](http://imgbed.momodel.cn/15-a1 step3.1.png)\n",
    "+ 第二步，训练\n",
    "\n",
    "![](http://imgbed.momodel.cn/15-a2 step3.2.png)\n",
    "+ 其中，x_train 和 y_train 都是 numpy array 的形式：\n",
    "\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/15-7 选择最佳的函数.png)\n",
    "其中：\n",
    "+ batch_size: 在实际操作中，我们并不会最小化总的损失函数，而是把训练集分成多个 batch，每次最小化一个 batch 的总损失 —— 小批量梯度下降法（Mini-batch）。\n",
    "+ nb_epoch: 将所有的 batch 都跑一遍叫做一个 epoch。\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/15-8 Mini-batch.png)    \n",
    "![](http://imgbed.momodel.cn/15-9 batch size.png)\n",
    "+ 如果 batch_size 设为1，小批量梯度下降法（Mini-batch Gradient Descent）就相当于随机梯度下降法（SGD）。\n",
    "+ 随机梯度下降法特点是参数更新的更快，不稳定。小批量梯度下降法特点是参数更新慢，更稳定。\n",
    "+ 实际操作中，相同时间内，两种梯度下降算法参数更新的次数相当，所以我们更倾向于稳定的小批量梯度下降法。\n",
    "    \n",
    "![](http://imgbed.momodel.cn/15-10 对速度的影响.png)    \n",
    "+ Batch_size 不能过大的原因：1. GPU 平行运算的能力是有限度的；2. 容易陷入局部最优点（这也是 SGD 的随机性可以解决的问题）。\n",
    "+ 小批量梯度下降法比随机梯度下降法更快的原因是前者可以调用 GPU 平行运算：\n",
    "    \n",
    "![](http://imgbed.momodel.cn/15-12 随机梯度下降和minibatch.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Keras 补充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ 保存和加载模型： <font size=3.5>http://keras.io/getting-started/faq/#how-can-i-save-a-keras-model <font>\n",
    "\n",
    "+ 帮你做测试：1. 有测试集的情况下算正确率（score[0]:损失，score[1]:正确率） 2. 只有输入的情况下做预测。\n",
    "\n",
    "![](http://imgbed.momodel.cn/15-13 测试.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
