{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 这一节我们主要学习\n",
    "\n",
    "+ 介绍 Auto-encoder\n",
    "+ 深度自动编码\n",
    "+ 深度自动编码实例化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 介绍 Auto-encoder <br>\n",
    "\n",
    "基本上 Auto-encoder 是使用神经网络进行降維。<br>\n",
    "编码器（Encoder）将输入降维成一段 code ；然后通过解码器（Decoder）进行解码输出。最终目标是让输入和输出相等或十分接近。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_01_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在手写数字识别任务中，想训练一个 NN encoder ，得到图像的精简表达。<br>\n",
    "但做的是无监督学习，可以找到很多 input image ，但是不知道 code 最终结果无法计算误差，所以没法学习更新编码器（NN Encoder）。<br>\n",
    "于是又提出一个 NN decoder（也没法单独更新），把两者连接在一起通过比较输入和输出的误差更新编码器和解码器 。<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_02_ul_pca.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA 过程回顾：<br>\n",
    "首先通过输入的图片，乘以矩阵W，得到降维后的数据，<br>\n",
    "然后对于降维数据乘以前述矩阵的转置，可以得到预测的输出图片。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 深度自动编码\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_03_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当这个结构变得很深，就变成了deep auto-encoder，encoder 和 decoder 的系数不一定是对称的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_04_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上图上面部分是手写数字采用 PCA 降维:把784维降到30维再恢复到784维<br>\n",
    "下面是采用 deep auto-encoder 降维：784-1000-500-250-30-250-500-1000-784<br>\n",
    "PCA&Deep Auto-encoder 比较，明显后者效果更好。<br>\n",
    "不过以上不是重点，重点如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_05_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当 code 为二维时，很明显看到 Deep Auto-encoder 使数字手写识别集分类地更好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 添加噪声"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_06_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了让 auto-encoder 学的更好，我们可以在输入加入噪音"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 深度自动编码实例化\n",
    "\n",
    "\n",
    "\n",
    "#### 3.1 应用于图片\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_07_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接对像素做 t-SEN ，把 PCA 降维到32维，颜色分开效果还好。<br>\n",
    "与上面 Deep auto-encoder 对比:<br>\n",
    "1成功的被分开了，4与9与分开没有很明显，但是效果比原本混在一起好。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 应用于文字处理\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_08_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把文章变成一段 code ，得到 vector space model ，<br>\n",
    "把查询词汇也变成一个 vector ，从而进行查询。<br> \n",
    "比如图中与查询的向量接近的为红色左边和右边的文章向量，将向量解码后可能就是所查询得到的结果<br>\n",
    "一种方法是**词袋**，但是这种方法中每个词都独立，不能知道语意。<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_09_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要把语意考虑进来的话，要用 Auto-encoder 。<br>\n",
    "词袋经过 auto-encoder 之后得到 code 。上图中不同颜色代表文档的不同种类。<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 应用于以图找图\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_10_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果基于像素计算图片之间相似度的话，得到的结果会比较差。<br>\n",
    "比如，会得到迈克尔杰克逊的照片比较像马蹄铁。 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_11_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "直接图像像素查找的效果不是太理想，选用深度自动编码，<br>\n",
    "先把图像像素作为 input ，总共5层，直至编码成256维度。<br>\n",
    "图片右上角是编码后解码回来的图像，比原图像模糊。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_12_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用编码后256维的信息寻找相似度接近的，结果就会好很多，最起码都是人脸了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 应用在CNN中\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_13_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要增加的隐藏层有 deconvolution 和 unpooling <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_14_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于 unpooling ，我们只需要在 maxpooling 过程中把要把 max locations 记录下来，<br>\n",
    "然后 unpooling 时候还原其位置，其他全为0<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_15_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "而 deconvolution 实质上就是 convolution 。<br>\n",
    "中间从三维扩展成五维的过程相当于右边通过CNN将七维降成5维（灰色的输入代表0）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Pre-train DNN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-encoder 还可以Pre-train DNN，第一步先将784维的数据转换成1000维，再将1000维的数据解码转换成784维，这样就可以通过比较先后784维度的数据更新得到w1。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_16_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二步可以得到 w2 ，依次类推"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_17_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把 w1,w2,w3 当做初始的参数，把最后 output 接上去，再用反向传播更新所有参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_18_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练第一个 auto-encoder 时，由于 hidden layer 的维数大于 input 维数，要加很强的正则项，<br>\n",
    "e.g.: 对1000维的输出做L1正则化（希望 output 稀疏）。<br>\n",
    "否则 hidden layer 可能直接记住 input ，没有 learn 到任何东西。 <br>\n",
    "在训练第二个 auto-encoder 时，要把数据集中所有 digit 都变成1000维vector。 <br>\n",
    "以此类推，最后随机初始化输出层之前的权重。然后用反向传播做 fine-tune （W1,W2,W3已经很好，微调即可）。<br> \n",
    "<br>\n",
    "之前在训练较深的NN时要用到预训练，但是现在没必要了，因为训练技术进步了。 <br>\n",
    "但在有大量无标注数据 、少量标注数据时仍需要预训练，<br>\n",
    "可以先用大量无标注数据先把W1,W2,W3先训练好，最后的标注的数据只需稍微调整权重就好。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你想了解更多，下面是关于restricted Boltzmann machine的资料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Neural networks [5.1] : Restricted Boltzmann machine–definition\n",
    "    + https://www.youtube.com/watchv=p4Vh_zMwHQ&index=36&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrN\n",
    "<br>\n",
    "+ Neural networks [5.2] : Restricted Boltzmann machine–inference\n",
    "    +  https://www.youtube.com/watchv=lekCh_i32iE&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=37\n",
    "<br>\n",
    "+ Neural networks [5.3] : Restricted Boltzmann machine - free energy\n",
    "    + https://www.youtube.com/watchv=e0Ts_7Y6hZU&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=38\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面是关于deep belief network的资料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+  Neural networks [7.7] : Deep learning - deep belief networks\n",
    "    + https://www.youtube.com/watchv=vkb6AWYXZ5I&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=57\n",
    "<br>\n",
    "+ Neural networks [7.8] : Deep learning - variational bound\n",
    "    + https://www.youtube.com/watchv=pStDscJh2Wo&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=58\n",
    "<br>\n",
    "+ Neural networks [7.9] : Deep learning - DBN pre-training\n",
    "    + https://www.youtube.com/watchv=35MUlYCColk&list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&index=59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder 还可以生成我们想要的东西，比如图像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_20_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://imgbed.momodel.cn/27_19_ul_ae.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "784维降到2维，根据向量的分布选择红框，在红框中等间隔采样，<br>\n",
    "作为解码的输入，得到计算机生成的图片。<br> \n",
    "如果红框选错了位置，比如选在右下方，可能得不到数字。<br> \n",
    "“需知道词向量分布”略麻烦，改进方法：加正则化。 <br>\n",
    "在训练时，对 code 加L2正则化，这样 code 比较接近0。<br>\n",
    "采样时在0附近采样，这样采样得到的词向量比较有可能都对应数字。<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 总结\n",
    "+ Auto-encoder 原理\n",
    "+ Deep Auto-encoder 原理及其应用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
