{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 这节我们主要学习\n",
    "\n",
    "+ 回顾一下结构化学习的模型\n",
    "+ 可分离的情况\n",
    "+ 不可分离的情况\n",
    "+ 结构化支持向量机\n",
    "+ 切割平面法\n",
    "+ 多分类支持向量机\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 结构化学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "+ 我们需要一个功能更强大的函数$f$\n",
    "  + 输入和输出都是具有结构的对象\n",
    "  + 对象：序列，列表，树，边界框$...$\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-1 structured learning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 统一框架"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-2 unified work.png)\n",
    "分为 Training 和 Testing 两个部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 三个问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "+ $F(x,y)$ 长什么样子\n",
    "+ 怎样求解 **arg max** 问题\n",
    "+ 如何找到$F(x,y)$\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-3 problems.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 实例任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-4 task.png)\n",
    "在本节课程中，我们使用目标检测的例子进行讲解；\n",
    "\n",
    "但我们今天学习到的内容同样可以用作其他任务.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**问题1：估算**</font>\n",
    "\n",
    "**假设 $F(x,y)$ 是线性的**\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-5 problem1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**问题2：推理**</font>\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-6 problem2.png)\n",
    "找到使 $F(x,y)$ 最大的 $\\tilde y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "求解 <font size=4>$\\tilde y$ </font> 的方法\n",
    "\n",
    "+ 目标检测\n",
    "    + 分支定界算法\n",
    "    + 选择性搜索\n",
    " \n",
    "+ 序列标记\n",
    "    + 维特比算法\n",
    " \n",
    "+ 算法依赖于 $\\phi (x,y)$\n",
    "\n",
    "+ 遗传算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4>**问题3：训练**</font>\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-7 proble3.png)\n",
    "数据集对应的 $F(x,y)$ 应该是最大的\n",
    "\n",
    "接下来我们忽略问题 1 和问题 2，直接关注于问题 3。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 可分离的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "假设：可分离\n",
    "\n",
    "+ 权重向量 $\\hat w$ 存在,使得所有红色标记点的乘积的值大于其余蓝色点的乘积的值加上 $\\delta$（红色代表是正确的，蓝色代表是错误的）\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-8 separable.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 结构感知器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-9 structured perceptron.png)\n",
    "**当 $w$ 不再更新的时候，算法结束。**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 数学证明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "在可分离的案例中，为了获得 $\\hat w$，最多需要更新 $(\\frac {R} {\\delta})^2$ 次\n",
    "\n",
    "$\\delta：$边距；\n",
    "\n",
    "$R:$ $\\phi(x,y)$ 和 $\\phi (x,y')$ 之间的最大距离"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 当看见一个错误的时候，$w$ 进行更新\n",
    " \n",
    "\n",
    "![](http://imgbed.momodel.cn/34-10 update.png)\n",
    "在可分离的案例中，我们不是一般性地设 $\\hat w$ 的长度为 1（若 $\\hat w$ 的长度不为 1，但是对其标准化之后，这依然是一个可分离的问题）\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-11 remind12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "随着 $k$ 的增加，$\\hat w$ 和 $w^k$ 之间的夹角 <font size=4>$\\rho_k$</font> 越来越小。\n",
    "\n",
    "<font size=4>$cos\\rho_k= \\frac{\\hat w}{\\|\\hat w\\|}$</font>\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-12 delta.png)\n",
    "如图，分子 $\\hat w \\cdot w^k$ 的值随着 $k$ 的增大越来越大\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-13 proof.png)\n",
    "分母，我们之前假设 $\\hat w$ 的长度为1，确定 $w^k$ 的长度即可。\n",
    " \n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-14 long distance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "夹角的余弦值为：\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-15 cos.png)\n",
    "余弦值的下界会不断增加，但余弦值不会超过1；\n",
    "\n",
    "所以$k$要小于等于$(\\frac {R} {\\delta})^2$，即最多需要更新$(\\frac {R} {\\delta})^2$次"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何让训练更快？\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-16 fast.png)\n",
    "当边距越大的时候，训练越快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 不可分离的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "当数据不能完全分离的时候，我们依旧可以判断某些权重比其他的权重更好。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-17 non separable.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一个损失 $C$ 来估计权重 $w$ 到底有多差，我们需要选择最小化损失 $C$ 的 $w$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失的定义如下：\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-18 cost.png)\n",
    "用所有可能y得到的最大值减去训练样本对应的值，得到最后的损失函数的值（都是大于等于 0 的）。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 随机梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "$C^n=max[w\\cdot \\phi (x^n,y)]-w\\cdot \\phi (x^n,\\hat y^n)$\n",
    "\n",
    "由于存在 $max$ 函数，当 $w$ 在不同的区域的时候，$y$ 的取值是不一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算梯度：\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-19 gradient.png)\n",
    "随机选取一个训练数据，确定 $y$ 在 $w$ 的哪个区域中，然后采用梯度下降法进行更新。\n",
    "\n",
    "当 $\\eta$=1 的时候，我们实际上是在处理结构化感知器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 考虑误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-20 error.png)\n",
    "之前，我们并没有考虑不正确的 $y$ 的差异性，实际上右边的情况，比左边的要好很多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以，我们需要考虑不正确的 $y$ 之间的好坏。\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-21 consider.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义误差函数：\n",
    "\n",
    "$\\Delta (\\hat y,y)$：y 和 $\\hat y$ 之间的误差（是大于 0 的）\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-22 error function.png)\n",
    "当 $\\hat y$ 和 $y$ 之间完全没有重叠的时候，误差最大为 1；\n",
    "\n",
    "当 $\\hat y$ 和 $y$ 之间重合的时候，误差为 0。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-23 another.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-24 gradient descent.png)\n",
    "我们需要找到新的函数的最大值，因此我们需要设计一个较好的误差，让这个最大值能够解出来；\n",
    "\n",
    "其余部分与改良前的算法没有什么区别。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "+ 最小化新的损失函数是最小化训练集上误差的上限\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-25 upper bound.png)\n",
    "$C'$ 误差可能出现阶梯状的情况，影响梯度更新；我们使用新的损失函数 $C$ 来代替；\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](http://imgbed.momodel.cn/34-26 proof upper.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-27 more function.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 正则化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "当训练集数据和测试集数据属于不同的分布的时候，$w$ 接近0可以消除 mismatch 的影响。\n",
    "\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-28 regularization.png)\n",
    "原始的损失函数可以让错误的答案与正确答案之间保持间距；\n",
    "\n",
    "正则化能够让 $w$ 接近 0。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-29 weight decay.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 结构化支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "我们需要找到 $w$，使损失函数达到最小。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-30 structured svm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "由于我们需要最小化损失函数，所以上式和下面的不等式相等（将 $w \\cdot \\phi(x^{n},\\hat y^{n})$ 移到等式左边）。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-31 equivalent.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将 $C^n$ 称为松弛变量，使用 $\\epsilon$ 来表示。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-32 slack variable.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于任意的 $y$ 不等于 $\\hat y$,上述不等式均成立。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-33 epsilon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-34 possible.png)\n",
    "我们可能会遇到不存在 w 使 w 与 $\\phi (x^n,\\hat y^n)$ 的乘积满足 margin 的要求，\n",
    "\n",
    "所以，可以使用松弛变量来减小不等式的约束。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-35 slack.png)\n",
    "不让不等式的约束无限减小，$\\epsilon$ 应该竟可能的小。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](http://imgbed.momodel.cn/34-36 summation.png)\n",
    "在满足不等式的情况下，我们希望 $\\epsilon$ 的和最小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![](http://imgbed.momodel.cn/34-37 sun.png)\n",
    "我们在最小化损失函数同时，需要满足上面的约束条件。\n",
    "\n",
    "$y$ 的取值有成千上万中可能，当限制条件这么多情况下，我们应该如何求解最小值？\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 切割平面算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "我们需要在满足下面约束条件的情况下，求得损失函数的最小值。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-38 cut plane.png)\n",
    "\n",
    "根据不同的约束条件，我们可以将曲面分成不同的区域，求得对应区域的最小值。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-39 curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-40 parameter space.png)\n",
    "不同的约束条件将参数空间分割成不同的部分。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-40 working set.png)\n",
    "尽管这里众多的约束条件，但是真真起作用的还是红色线条表示的部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "+ 元素被不断迭代地选入工作集\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-41 iterative.png)\n",
    "每次迭代之前，都会有一个工作集，计算 $w$，\n",
    "\n",
    "然后选择合适的元素加入工作集，进行下一次迭代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 将元素逐渐添加到工作集中\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-42 null.png)\n",
    "我们初始化工作集为空集，计算得到（二次规划问题）一个 $w$,\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-44 most.png)\n",
    "然后找到最不满足当前约束条件的元素加入到工作集中,不断迭代。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 找到最不满足约束的元素\n",
    "\n",
    "当$w$和$\\epsilon$确定之后，如何寻找最不满足约束条件的 $y$：\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-45 find.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-47 repeat.png)\n",
    "+ 初始化每个训练集数据的工作集为空；\n",
    "\n",
    "+ 不断循环直到每个工作集不再改变：\n",
    " + 在相应的工作集下，利用[二次规划](https://baike.baidu.com/item/%E4%BA%8C%E6%AC%A1%E8%A7%84%E5%88%92)求解 $w$\n",
    " + 对于每一个训练数据，找到最违反规则的 y\n",
    " + 将该元素加入到相应的工作集进行更新\n",
    "\n",
    "+ 返回 $w$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.多分类支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "我们可以用结构化学习的框架来处理多分类问题：\n",
    "\n",
    "+ 评估：\n",
    " + 如果有K类，那么我们有K个权重向量{$w^1,w^2,...,w^K$}\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-49 problem1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 推理：\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-50 inference.png)\n",
    "类的数量通常很小，所以我们可以枚举它们。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 训练\n",
    "\n",
    "由于约束条件比较少，我们直接穷举即可。\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-51 训练.png)\n",
    "当两个类别差别较大时，我们可以将 $\\Delta$ 的值设置的较大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-52 binary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 深度神经网络与结构化支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "前面我们学习的结构化模型都是线性的，功能不是很强大；\n",
    "\n",
    "+ 使用深度神经网络生成较为强大的模型，\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-53 beyond.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 将结构化支持向量机和深度神经网络一起训练\n",
    "\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-54 join.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 将结构化支持向量机用深度神经网络代替，变成更深的神经网络\n",
    "\n",
    "![](http://imgbed.momodel.cn/34-55 replace.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
