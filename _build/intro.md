---
title: '目录声明'
prev_page:
  url: 
  title: ''
next_page:
  url: https://github.com/jupyter/jupyter-book
  title: '课程链接'
comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---
## 台大李宏毅教授机器学习课程指引

**中文世界中最好的机器学习课程！**
**李宏毅老师的机器学习和深度学习系列课程，是中文世界中最好！课程中有深入浅出的讲解和幽默生动的比喻。关键一切都是中文的！**

# **一、课程目录及主要内容：**

## 第1章 机器学习介绍
### 01 机器学习导论

+ 人工智能发展史</br>
+ 人工智能、机器学习、深度学习关系
+ 什么是机器学习？
+ 机器学习路线

### 02 我们为什么需要去学习机器学习

- AI 训练师

## 第2章 回归模型
### 01 回归模型案例

- 线性回归模型的应用场景
- 线性回归模型的原理和实现流程
- 梯度下降法
- 过拟合产生的原因以及解决方法
- 正则化

### 02 梯度下降法实战(Python)

- 机器学习常见的 Python 包
- 梯度下降法代码实现

### 03 误差分析

- 误差的来源
- 偏差
- 方差
- 过拟合、欠拟合与误差的关系
- 交叉验证

### 04 梯度下降法

+ 梯度下降法流程
+ 调整学习率之Adagrad法
+  随机梯度下降法的原理及优缺点
+ 特征放缩

### 05 梯度下降法

+ 游戏理解梯度下降法，如何找到局部最低点或者全局最低点

### 06 梯度下降法

+ 理解梯度下降法更新参数时，loss 出现不降反增的情况 

### 07 作业介绍

## 第3章 分类模型

### 01 分类

+ 分类模型
+ 最大似然估计
+ 概率分布、先验概率、后验概率及条件概率

### 02 逻辑回归

+ 逻辑回归模型
+ 逻辑回归与平方误差
+ 判别模型与生成模型
+ 多元分类
+ 逻辑回归的优缺点

### 03 作业介绍

## 第4章 深度学习
### 01 介绍深度学习

+ 深度学习的发展历史以及流程
+ 神经网络
+ 全连接前馈网络
+ 损失函数
+ 反向传播

### 02.反向传播

+ 梯度下降法
+ 链式法则
+ 前向传播
+ 反向传播

### 03.基于Keras实现的深度学习的Hwllo World

+ Keras 简介
+ 用 Keras 实现手写数字识别模型
+ 小批量梯度下降（Mini-batch Gradient Descent）

### 04 Keras2.0 实现手写数字识别

### 05 Keras demo1

### 06.DNN训练技巧

+ 激活函数（activation function）
+ 自适应学习率（Adaptive Learning Rate）
+ 早停法（Early Stopping）
+ 正则化（Regularization）
+ Dropout

### 07.Keras demo

### 08.Fizz Buzz in Tensorflow

## 第5章 卷积神经网络

### 01. 卷积神经网络

+ 介绍卷积神经网络（CNN）
+ 卷积神经网络主要内容
+ 在Keras中实现CNN
+ 理解CNN实际在做什么
+ CNN的一些应用

### 02.深度学习的原因

+ 胖+短的网络 VS. 瘦+高的网络
+ 神经网络模块化思想
+ 端到端学习
+ 深层网络在处理复杂问题中的作用

## 第6章 半监督学习
### 01.半监督学习

+ 生成模型中的半监督学习
+ 低密度分离
+ 平滑性假设
+ 更好的表达

## 第7章 无监督学习
### 01 线性降维

+ 无监督学习的分类
+ 聚类
+ 分布式表征
+ 降维
+ PCA 主成分分析
+ 矩阵分解

### 02 词嵌入

+ 为什么要使用词嵌入
+ 为什么词嵌入是无监督学习
+ 基于统计
+ 基于预测
+ 词嵌入的特点
+ 词嵌入的主要应用

### 03 邻域嵌套

+ 流形学习
+ 局部线性嵌入
+ 拉普拉斯特征映射
+ T-distributed Stochastic Neighbor Embedding (t-SNE)

### 04 深度自动编码

+ 介绍 Auto-encoder
+ 深度自动编码
+ 深度自动编码实例化

### 05 生成器1

+ 生成模型
+ 像素循环神经网络
+ 变分自编码器

###  06 生成器2

+ 为什么使用VAE
+ 高斯混合模型
+ VAE的问题
+ 生成对抗网络

## 第8章 迁移学习

###  01.迁移学习

+ 介绍迁移学习
+ 模型微调
+ 多任务学习
+ 领域对抗训练
+ Zero-shot Learning

## 第9章 结构化学习
### 01.支持向量机

+ 支持向量机的介绍
+ Hinge Loss
+ 线性支持向量机
+ 核方法

### 02.结构化学习

+ 结构化学习介绍
+ 结构化学习的统一框架
+ 结构化学习中需要解决的几个问题

### 03.结构化线性模型

### 04.结构化支持向量机

+ 结构化学习模型
+ 可分离的情况
+ 不可分离的情况
+ 结构化支持向量机
+ 切割平面法
+ 多分类支持向量机

### 05.序列标记

+ 序列标签
+ 隐马尔科夫模型
+ 条件随机场
+ 结构感知器和结构化支持向量机

## 第10章 RNN与集成学习
### 01.循环神经网络1

+ 应用实例：插槽填充
+ RNN 网络的介绍
+ 长短期记忆网络（LSTM）的介绍与详解

### 02.循环神经网络2

+ RNN原理
+ 解决梯度消失或者梯度爆炸的方法
+ RNN 应用
+ Sequence to sequence
+ 基于注意力模型
+ RNN与结构化学习的联系与区别

### 03.集成学习

+ 集成学习的介绍
+ Bagging 
+ Boosting
+ Stacking

### 04.深度强化学习

+ 深度强化学习的概念和几个应用场景
+ 用基于策略的方法（Policy-based）学习一个做事的 Actor
+ 用基于价值的方法（Value-based）学习一个批评的 Critic(下学期内容)
+ 将 Actor 与 Critic 结合得到当前最强的方法 A3C（下学期内容）

## 第11章 总结与展望
### 01.机器学习的下一步

+ 异常检测
+ 可解释型 AI
+ 对抗攻击
+ 终生学习
+ 元学习
+ 小（零）样本学习
+ 强化学习
+ 网络压缩
+ 无监督域适应

# 二.课程参考资料声明

本份课程资料主要是基于2017年台湾大学老师李宏毅老师的机器学习课程资料

+ 视频网址：https://www.bilibili.com/video/av10590361/?p=1
+ 课程资料：http://speech.ee.ntu.edu.tw/~tlkagk/courses.html 

在整理资料的过程中，参考的资料有：

+ 博客：https://blog.csdn.net/dukuku5038/article/details/82253966
+ 博客：https://blog.csdn.net/xzy_thu/article/details/67640512
+ 资料：https://github.com/maplezzz/NTU_ML2017_Hung-yi-Lee_HW
+ 资料：https://github.com/dafish-ai/NTU-Machine-learning 


此外，该资料还参考机器学习、深度学习相关的论文书籍等，在这就不一一列举。

如果有侵权行为，请联系我们。

考虑编著们水平有限，资料中难免有错误或者解释不清之处，欢迎大家批评指正和进一步的补充。
